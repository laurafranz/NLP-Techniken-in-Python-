{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "843714c5-7013-4d25-8204-139f11913378",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "import regex as re\n",
    "import string\n",
    "import spacy\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "#nltk.download('punkt')\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim import corpora, models\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "from gensim.corpora import Dictionary\n",
    "\n",
    "#%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.table import Table\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim_models\n",
    "\n",
    "import warnings, logging\n",
    "warnings.filterwarnings(\"ignore\",category=DeprecationWarning)\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.ERROR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35479e97-490b-40af-ad58-e3c791692ba5",
   "metadata": {},
   "source": [
    "# Daten laden und vorverarbeiten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "f874e935",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file_path):\n",
    "    df = pd.read_csv(file_path, encoding='utf-8')\n",
    "    return df\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Remove punctuation and convert to lowercase\n",
    "    text = re.sub(f\"[{re.escape(string.punctuation)}]\", ' ', text)\n",
    "    text = re.sub(r\"\\d+\", \" \", text)\n",
    "    text = text.strip().replace('\\n', ' ')\n",
    "    text = text.lower()\n",
    "    return text\n",
    "\n",
    "def tokenize_text(text):\n",
    "    return word_tokenize(text, language='german')\n",
    "\n",
    "def make_bigrams(data_words):\n",
    "    return [bigram_mod[data] for data in data_words]\n",
    "\n",
    "def make_trigrams(data_words):\n",
    "    return [trigram_mod[bigram_mod[data]] for data in data_words]\n",
    "\n",
    "def lemmatize(texts, nlp, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n",
    "    texts_out = []\n",
    "    for text in texts:\n",
    "        doc = nlp(\" \".join(text))\n",
    "        texts_out.append([token.lemma_ for token in doc if token.pos_ in allowed_postags])\n",
    "    texts_out = [[word for word in simple_preprocess(str(text)) if word not in stop_words] for text in texts_out]\n",
    "    return texts_out\n",
    "\n",
    "def build_dictionary_and_corpus(data_ready):\n",
    "    id2word = Dictionary(data_ready) # fit dictionary\n",
    "    \n",
    "    print(f\"Vokabular vor der Filterung: {len(id2word)} Wörter\")\n",
    "    # Filtere das Vokabular\n",
    "    id2word.filter_extremes(no_below=5, no_above=0.40, keep_n=10000)\n",
    "    print(f\"Vokabular nach der Filterung: {len(id2word)} Wörter\")\n",
    "    \n",
    "    bow_corpus = [id2word.doc2bow(text, allow_update=True) for text in data_ready]\n",
    "    return id2word, bow_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "602e30bd-aa23-4b62-9454-e7f2b801579c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "url = \"https://ordnungsamt.berlin.de/frontend.webservice.opendata/api/meldungen\"\n",
    "\n",
    "#get the data from url\n",
    "response = requests.get(url).json()\n",
    "df = pd.json_normalize(response, record_path=['index'])\n",
    "df.replace(to_replace=[None], value='', inplace=True)\n",
    "\n",
    "#New column after customer complaints are processed with function to clean up and lemmatize.\n",
    "df['sachverhalt_clean'] = df['sachverhalt'].map(preprocess_text)\n",
    "data = df['sachverhalt_clean'].values.tolist()\n",
    "\n",
    "#tokenize\n",
    "words_tokenized = [tokenize_text(sentence) for sentence in data]\n",
    "\n",
    "#remove stopwords\n",
    "stop_words = stopwords.words('german')\n",
    "custom_stopwords = ['geehrt', 'damen', 'und', 'herren', 'schon', 'herr', 'dame', 'grüßenk', 'geehrte_damen', 'vsehr', 'mal', 'seeehr', 'grüßenstefanie', 'lieb', 'berlintel', 'mit_freundlich', 'auf_dem', 'hiermit', 'soweit', 'zudem', 'siehe_foto', 'nicht_mehr', 'mehr_als']\n",
    "stop_words.extend(custom_stopwords)\n",
    "\n",
    "# make bigram and trigram\n",
    "bigram = gensim.models.Phrases(words_tokenized, min_count=5, threshold=15)\n",
    "trigram = gensim.models.Phrases(bigram[words_tokenized], threshold=15)\n",
    "bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
    "trigram_mod = gensim.models.phrases.Phraser(trigram)\n",
    "\n",
    "words_bigram = make_bigrams(words_tokenized)\n",
    "words_trigram = make_trigrams(words_tokenized)\n",
    "\n",
    "#lemmatize and remove stop words\n",
    "#!python -m spacy download de_core_news_sm\n",
    "nlp = spacy.load(\"de_core_news_sm\")\n",
    "data_ready = lemmatize(words_trigram, nlp, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV'])\n",
    "data_ready = [x for x in data_ready if x] #remove empty lists from list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "d90a5a26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vokabular vor der Filterung: 6274 Wörter\n",
      "Vokabular nach der Filterung: 1039 Wörter\n"
     ]
    }
   ],
   "source": [
    "# create dictionary and corpus\n",
    "id2word, bow_corpus = build_dictionary_and_corpus(data_ready)\n",
    "bow_corpus = [x for x in bow_corpus if x] # remove empty lists from list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5154512-dec5-48d2-9a74-49d721bcf07d",
   "metadata": {},
   "source": [
    "# Besten Model finden und implementieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "5e600db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_tfidf_model(bow_corpus, id2word, smartire):\n",
    "    tfidf_model = models.TfidfModel(bow_corpus, dictionary=id2word, smartirs=smartire)\n",
    "    tfidf_corpus = tfidf_model[bow_corpus]\n",
    "    return tfidf_model, tfidf_corpus\n",
    "\n",
    "def calculate_lsa_perplexity(model, corpus):\n",
    "    count = len(corpus) #number of documents in the corpus\n",
    "    log_likelihood = 0.0\n",
    "    nonzero_count = 0  # Zählt die nicht-negativen Wahrscheinlichkeiten\n",
    "\n",
    "    for doc in corpus:\n",
    "        topics = model[doc] #retrieves the topics and their probabilities for the current document from model\n",
    "        for topic, prob in topics:\n",
    "            if prob >= 0:\n",
    "                # accumulates the log likelihood of the document, \n",
    "                # adding a small constant (1e-10) to avoid issues with taking the logarithm of very small probabilities\n",
    "                log_likelihood += np.log(prob + 1e-10) # Add a small constant to avoid log(0)\n",
    "                nonzero_count += 1\n",
    "\n",
    "    # Überprüfen, ob es mindestens eine nicht-negative Wahrscheinlichkeit gab\n",
    "    if nonzero_count > 0:\n",
    "        perplexity = np.exp(-log_likelihood / nonzero_count)\n",
    "    else:\n",
    "        perplexity = np.inf  # If there are zero non-zero probabilities, the perplexity is set to infinity\n",
    "\n",
    "    return perplexity\n",
    "\n",
    "def calculate_coherence_perplexity(corpus, n, alpha, beta, id2word, data_ready, model_type):\n",
    "    if model_type == \"LDA TF-IDF\" or model_type == \"LDA BoW\":\n",
    "        model = gensim.models.LdaModel(corpus=corpus, id2word=id2word, num_topics=n, random_state=42,\n",
    "                                           update_every=0, decay=0.9, chunksize=100, passes=30, alpha=alpha,\n",
    "                                           per_word_topics=True, eta=beta)\n",
    "        perplexity = -model.log_perplexity(corpus)\n",
    "    elif model_type == \"LSA TF-IDF\" or model_type == \"LSA BoW\":\n",
    "        model = gensim.models.LsiModel(corpus=corpus, id2word=id2word, num_topics=n, random_seed=42, decay=0.9, chunksize=100, power_iters=30)\n",
    "        perplexity = calculate_lsa_perplexity(model, corpus)\n",
    "    \n",
    "    coherence_model = CoherenceModel(model=model, texts=data_ready, dictionary=id2word, coherence='c_npmi') \n",
    "    coherence = coherence_model.get_coherence()\n",
    "    \n",
    "    return coherence, perplexity\n",
    "\n",
    "def find_best_model_parameters(corpus, id2word, data_ready, no_topics, alpha_list, beta_list, model_type):\n",
    "    best_coherence = -np.inf\n",
    "    best_parameters = None\n",
    "\n",
    "    if model_type == \"LDA BoW\":\n",
    "        for n in no_topics:\n",
    "            for alpha in alpha_list:\n",
    "                for beta in beta_list:\n",
    "                    coherence, perplexity = calculate_coherence_perplexity(corpus, n, alpha, beta, id2word, data_ready, model_type)\n",
    "                    if coherence > best_coherence:\n",
    "                        best_coherence = coherence\n",
    "                        best_parameters = n, alpha, beta\n",
    "    else: #LSA\n",
    "        for n in no_topics:\n",
    "            coherence, perplexity = calculate_coherence_perplexity(corpus, n, alpha_list[0], beta_list[0], id2word, data_ready, model_type)\n",
    "            if coherence > best_coherence:\n",
    "                best_coherence = coherence\n",
    "                best_parameters = n, alpha_list[0], beta_list[0]\n",
    "\n",
    "    return best_parameters\n",
    "\n",
    "def find_best_model_parameters_tfidf(corpus, id2word, data_ready, no_topics, alpha_list, beta_list, model_type):\n",
    "    best_coherence = -np.inf\n",
    "    best_parameters = None\n",
    "    \n",
    "    smartirs_lda = ['dpn', 'bxn', 'bxu', 'bpb', 'bfb'] \n",
    "    smartirs_lsa = ['lpn', 'txn', 'tpn']\n",
    "\n",
    "    if model_type == \"LDA TF-IDF\":\n",
    "        for i in smartirs_lda:\n",
    "            # Create the TF-IDF model\n",
    "            tfidf_model = gensim.models.TfidfModel(corpus, dictionary = id2word, smartirs = i)\n",
    "            tfidf_corpus = tfidf_model[corpus]\n",
    "\n",
    "            for n in no_topics:\n",
    "                for alpha in alpha_list:\n",
    "                    for beta in beta_list:\n",
    "                        coherence, perplexity = calculate_coherence_perplexity(tfidf_corpus, n, alpha, beta, id2word, data_ready, model_type)\n",
    "                        if coherence > best_coherence:\n",
    "                            best_coherence = coherence\n",
    "                            best_parameters = n, alpha, beta, i\n",
    "    else:\n",
    "        for i in smartirs_lsa:\n",
    "            # Create the TF-IDF model\n",
    "            tfidf_model = gensim.models.TfidfModel(corpus, dictionary = id2word, smartirs = i)\n",
    "            tfidf_corpus = tfidf_model[corpus]\n",
    "\n",
    "            for n in no_topics:\n",
    "                coherence, perplexity = calculate_coherence_perplexity(tfidf_corpus, n, alpha_list[0], beta_list[0], id2word, data_ready, model_type)\n",
    "                if coherence > best_coherence:\n",
    "                    best_coherence = coherence\n",
    "                    best_parameters = n, alpha_list[0], beta_list[0], i\n",
    "                \n",
    "    return best_parameters\n",
    "    \n",
    "def plot_coherence(coherence_lda_bow, coherence_lda_tfidf, coherence_lsa_bow, coherence_lsa_tfidf, no_topics):\n",
    "    fig, ax1 = plt.subplots(figsize=(12, 6))\n",
    "    ax1.plot(no_topics, coherence_lda_bow, label=\"LDA BoW\")\n",
    "    ax1.plot(no_topics, coherence_lda_tfidf, label=\"LDA TF-IDF\")\n",
    "    ax1.plot(no_topics, coherence_lsa_bow, label=\"LSA BoW\")\n",
    "    ax1.plot(no_topics, coherence_lsa_tfidf, label=\"LSA TF-IDF\")\n",
    "    \n",
    "    ax1.set_xlabel('Anzahl der Themen')\n",
    "    ax1.set_ylabel(\"Koheränz\")\n",
    "    ax1.legend(loc='best')\n",
    "    ax1.set_title('Koheränz in Abhängigkeit von der Anzahl der Themen')\n",
    "\n",
    "    # Table data\n",
    "    data = [coherence_lda_bow, coherence_lda_tfidf, coherence_lsa_bow, coherence_lsa_tfidf]\n",
    "    data = [['%.2f' % j for j in i] for i in data] #round\n",
    "    rows = [\"LDA BoW\", \"LDA TF-IDF\", \"LSA BoW\", \"LSA TF-IDF\"]\n",
    "    columns = ['%d' % x for x in no_topics]\n",
    "    \n",
    "    # Add a table below the graph with the same size\n",
    "    ax2 = plt.gca().twiny()\n",
    "    ax2.axis(\"off\")\n",
    "    table = ax2.table(cellText=data, rowLabels=rows, colLabels=columns, rowLoc='center', loc='center', bbox=[0, -0.3, 1.0, 0.2])\n",
    "    table.auto_set_font_size(False)\n",
    "    table.set_fontsize(10)\n",
    "\n",
    "    # Set the size of ax2 to match the size of ax1\n",
    "    ax2.set_position(ax1.get_position())\n",
    "    \n",
    "    plt.savefig('coherence_score.png', bbox_inches='tight', dpi=150)\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "def plot_perplexity(perplexity_lda_bow, perplexity_lda_tfidf, perplexity_lsa_bow, perplexity_lsa_tfidf, no_topics):\n",
    "    fig, ax1 = plt.subplots(figsize=(12, 6))\n",
    "    ax1.plot(no_topics, perplexity_lda_bow, label=\"LDA BoW\")\n",
    "    ax1.plot(no_topics, perplexity_lda_tfidf, label=\"LDA TF-IDF\")\n",
    "    ax1.plot(no_topics, perplexity_lsa_bow, label=\"LSA BoW\")\n",
    "    ax1.plot(no_topics, perplexity_lsa_tfidf, label=\"LSA TF-IDF\")\n",
    "    \n",
    "    ax1.set_xlabel('Anzahl der Themen')\n",
    "    ax1.set_ylabel(\"Perplexität\")\n",
    "    ax1.legend(loc='best')\n",
    "    ax1.set_title('Perplexität in Abhängigkeit von der Anzahl der Themen')\n",
    "\n",
    "    # Table data\n",
    "    data = [perplexity_lda_bow, perplexity_lda_tfidf, perplexity_lsa_bow, perplexity_lsa_tfidf]\n",
    "    data = [['%.2f' % j for j in i] for i in data]\n",
    "    rows = [\"LDA BoW\", \"LDA TF-IDF\", \"LSA BoW\", \"LSA TF-IDF\"]\n",
    "    columns = ['%d' % x for x in no_topics]\n",
    "    \n",
    "    # Add a table below the graph with the same size\n",
    "    ax2 = plt.gca().twiny()\n",
    "    ax2.axis(\"off\")\n",
    "    table = ax2.table(cellText=data, rowLabels=rows, colLabels=columns, rowLoc='center', loc='center', bbox=[0, -0.3, 1.0, 0.2]) #[xmin, ymin, width, height]\n",
    "    table.auto_set_font_size(False)\n",
    "    table.set_fontsize(10)\n",
    "\n",
    "    # Set the size of ax2 to match the size of ax1\n",
    "    ax2.set_position(ax1.get_position())\n",
    "    \n",
    "    plt.savefig('perplexity.png', bbox_inches='tight', dpi=150)\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "def build_lda_model(corpus, id2word, n, alpha, beta):\n",
    "    lda_model = gensim.models.LdaModel(corpus=corpus, id2word=id2word, num_topics=n, \n",
    "                                       random_state=42, update_every=0, decay=0.9, \n",
    "                                       chunksize=100, passes=30, alpha=alpha,\n",
    "                                       per_word_topics=True, eta=beta)\n",
    "    return lda_model\n",
    "\n",
    "def build_lsa_model(corpus, id2word, n):\n",
    "    lsa_model = gensim.models.LsiModel(corpus=corpus, id2word=id2word, num_topics=n, random_seed=42, \n",
    "                                       decay=0.9, chunksize=100, power_iters=30)\n",
    "    return lsa_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "609cdf8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_model(corpus, id2word, data_ready, no_topics, alpha_list, beta_list, model_type):\n",
    "    corpus = corpus\n",
    "    \n",
    "    coherence = -np.inf\n",
    "    perplexity = -np.inf\n",
    "    \n",
    "    best_model = None\n",
    "    \n",
    "    if  model_type == \"LDA BoW\" or model_type == \"LSA BoW\":\n",
    "        n, alpha, beta = find_best_model_parameters(corpus, id2word, data_ready, no_topics, alpha_list, beta_list, model_type)\n",
    "        \n",
    "        if model_type == \"LDA BoW\":\n",
    "            best_model = build_lda_model(corpus, id2word, n, alpha, beta)\n",
    "        elif model_type == \"LSA BoW\":\n",
    "            best_model = build_lsa_model(corpus, id2word, n)\n",
    "        \n",
    "        coherence, perplexity = calculate_coherence_perplexity(corpus, n, alpha, beta, id2word, data_ready, model_type)\n",
    "        \n",
    "    elif model_type == \"LDA TF-IDF\" or model_type == \"LSA TF-IDF\":\n",
    "        n, alpha, beta, smartire = find_best_model_parameters_tfidf(corpus, id2word, data_ready, no_topics, alpha_list, beta_list, model_type)\n",
    "        tfidf, tfidf_corpus = build_tfidf_model(corpus, id2word, smartire)\n",
    "        #tfidf_id2word = Dictionary.from_corpus(tfidf_corpus)\n",
    "            \n",
    "        if model_type == \"LDA TF-IDF\":\n",
    "            best_model = build_lda_model(tfidf_corpus, id2word, n, alpha, beta)\n",
    "        elif model_type == \"LSA TF-IDF\":\n",
    "            best_model = build_lsa_model(tfidf_corpus, id2word, n)\n",
    "\n",
    "        coherence, perplexity = calculate_coherence_perplexity(tfidf_corpus, n, alpha, beta, id2word, data_ready, model_type)\n",
    "\n",
    "    print(f\"\\nBestes {model_type} Model:\")\n",
    "    if model_type == \"LDA TF-IDF\" or model_type == \"LDA BoW\":\n",
    "        print(f\"Die besten Parameter: Anzahl der Themen: {n}, Alpha: {alpha}, Beta: {beta}\")\n",
    "    else:\n",
    "        print(f'Der beste Parameter: Anzahl der Themen: {n}')\n",
    "    \n",
    "    if model_type == \"LDA TF-IDF\" or model_type == \"LSA TF-IDF\":\n",
    "        print(f'Der beste Parameter für TF-IDF: Smartire: {smartire}')\n",
    "        \n",
    "    print(f\"Koheränz: {coherence}\")\n",
    "    print(f\"Perplexität: {perplexity}\")\n",
    "\n",
    "    return best_model, corpus, coherence, perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "07fa857b",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_topics = range(2, 21, 1)\n",
    "alpha_list = [0.001, 0.01, 0.1, 0.5]  \n",
    "beta_list = [0.001, 0.01, 0.02, 0.1, 0.5] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "859ce026",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Bestes LDA BoW Model:\n",
      "Die besten Parameter: Anzahl der Themen: 2, Alpha: 0.5, Beta: 0.5\n",
      "Koheränz: -0.1384093377046739\n",
      "Perplexität: 8.150993666052978\n",
      "\n",
      "Bestes LDA TF-IDF Model:\n",
      "Die besten Parameter: Anzahl der Themen: 2, Alpha: 0.5, Beta: 0.5\n",
      "Der beste Parameter für TF-IDF: Smartire: bxn\n",
      "Koheränz: -0.1537891893625272\n",
      "Perplexität: 8.193209199371655\n",
      "\n",
      "Bestes LSA BoW Model:\n",
      "Der beste Parameter: Anzahl der Themen: 2\n",
      "Koheränz: -0.10245136185975384\n",
      "Perplexität: 232.12568919970792\n",
      "\n",
      "Bestes LSA TF-IDF Model:\n",
      "Der beste Parameter: Anzahl der Themen: 2\n",
      "Der beste Parameter für TF-IDF: Smartire: lpn\n",
      "Koheränz: 0.13857558515376384\n",
      "Perplexität: 1118.967523693542\n",
      "\n",
      "Bestes LDA BoW Model:\n",
      "Die besten Parameter: Anzahl der Themen: 3, Alpha: 0.001, Beta: 0.001\n",
      "Koheränz: -0.1646368766214199\n",
      "Perplexität: 9.998538223566287\n",
      "\n",
      "Bestes LDA TF-IDF Model:\n",
      "Die besten Parameter: Anzahl der Themen: 3, Alpha: 0.5, Beta: 0.1\n",
      "Der beste Parameter für TF-IDF: Smartire: bxu\n",
      "Koheränz: -0.16257740286213865\n",
      "Perplexität: 10.815747040018657\n",
      "\n",
      "Bestes LSA BoW Model:\n",
      "Der beste Parameter: Anzahl der Themen: 3\n",
      "Koheränz: -0.12928755774681097\n",
      "Perplexität: 181.97858294087547\n",
      "\n",
      "Bestes LSA TF-IDF Model:\n",
      "Der beste Parameter: Anzahl der Themen: 3\n",
      "Der beste Parameter für TF-IDF: Smartire: lpn\n",
      "Koheränz: 0.08326282458446975\n",
      "Perplexität: 569.3445151703805\n",
      "\n",
      "Bestes LDA BoW Model:\n",
      "Die besten Parameter: Anzahl der Themen: 4, Alpha: 0.5, Beta: 0.5\n",
      "Koheränz: -0.1718240817378799\n",
      "Perplexität: 8.406910901936852\n",
      "\n",
      "Bestes LDA TF-IDF Model:\n",
      "Die besten Parameter: Anzahl der Themen: 4, Alpha: 0.5, Beta: 0.1\n",
      "Der beste Parameter für TF-IDF: Smartire: bxn\n",
      "Koheränz: -0.17071227414111173\n",
      "Perplexität: 8.719056018456959\n",
      "\n",
      "Bestes LSA BoW Model:\n",
      "Der beste Parameter: Anzahl der Themen: 4\n",
      "Koheränz: -0.10199973341861975\n",
      "Perplexität: 102.85441881338231\n",
      "\n",
      "Bestes LSA TF-IDF Model:\n",
      "Der beste Parameter: Anzahl der Themen: 4\n",
      "Der beste Parameter für TF-IDF: Smartire: lpn\n",
      "Koheränz: 0.08785739528331983\n",
      "Perplexität: 410.10768153031574\n",
      "\n",
      "Bestes LDA BoW Model:\n",
      "Die besten Parameter: Anzahl der Themen: 5, Alpha: 0.5, Beta: 0.5\n",
      "Koheränz: -0.17906581207699274\n",
      "Perplexität: 8.522470358567695\n",
      "\n",
      "Bestes LDA TF-IDF Model:\n",
      "Die besten Parameter: Anzahl der Themen: 5, Alpha: 0.5, Beta: 0.02\n",
      "Der beste Parameter für TF-IDF: Smartire: bxu\n",
      "Koheränz: -0.1655533158632226\n",
      "Perplexität: 17.466965580678043\n",
      "\n",
      "Bestes LSA BoW Model:\n",
      "Der beste Parameter: Anzahl der Themen: 5\n",
      "Koheränz: -0.1308278109113463\n",
      "Perplexität: 145.45852210488772\n",
      "\n",
      "Bestes LSA TF-IDF Model:\n",
      "Der beste Parameter: Anzahl der Themen: 5\n",
      "Der beste Parameter für TF-IDF: Smartire: tpn\n",
      "Koheränz: 0.11617996475657488\n",
      "Perplexität: 278.2431524815957\n",
      "\n",
      "Bestes LDA BoW Model:\n",
      "Die besten Parameter: Anzahl der Themen: 6, Alpha: 0.5, Beta: 0.02\n",
      "Koheränz: -0.169945573080443\n",
      "Perplexität: 9.900164224195086\n",
      "\n",
      "Bestes LDA TF-IDF Model:\n",
      "Die besten Parameter: Anzahl der Themen: 6, Alpha: 0.5, Beta: 0.1\n",
      "Der beste Parameter für TF-IDF: Smartire: bxn\n",
      "Koheränz: -0.1654265449254772\n",
      "Perplexität: 8.947714063749585\n",
      "\n",
      "Bestes LSA BoW Model:\n",
      "Der beste Parameter: Anzahl der Themen: 6\n",
      "Koheränz: -0.07751369165036327\n",
      "Perplexität: 167.3825209194128\n",
      "\n",
      "Bestes LSA TF-IDF Model:\n",
      "Der beste Parameter: Anzahl der Themen: 6\n",
      "Der beste Parameter für TF-IDF: Smartire: tpn\n",
      "Koheränz: 0.09197627348002857\n",
      "Perplexität: 201.56659349323127\n",
      "\n",
      "Bestes LDA BoW Model:\n",
      "Die besten Parameter: Anzahl der Themen: 7, Alpha: 0.5, Beta: 0.5\n",
      "Koheränz: -0.18930137475807077\n",
      "Perplexität: 8.704209174891947\n",
      "\n",
      "Bestes LDA TF-IDF Model:\n",
      "Die besten Parameter: Anzahl der Themen: 7, Alpha: 0.5, Beta: 0.5\n",
      "Der beste Parameter für TF-IDF: Smartire: bxu\n",
      "Koheränz: -0.17398757563052697\n",
      "Perplexität: 10.175673263928394\n",
      "\n",
      "Bestes LSA BoW Model:\n",
      "Der beste Parameter: Anzahl der Themen: 7\n",
      "Koheränz: -0.04427335347827256\n",
      "Perplexität: 120.4760251227566\n",
      "\n",
      "Bestes LSA TF-IDF Model:\n",
      "Der beste Parameter: Anzahl der Themen: 7\n",
      "Der beste Parameter für TF-IDF: Smartire: tpn\n",
      "Koheränz: 0.07583222383209753\n",
      "Perplexität: 163.86861285336457\n",
      "\n",
      "Bestes LDA BoW Model:\n",
      "Die besten Parameter: Anzahl der Themen: 8, Alpha: 0.5, Beta: 0.001\n",
      "Koheränz: -0.18295783091462414\n",
      "Perplexität: 15.120287477829427\n",
      "\n",
      "Bestes LDA TF-IDF Model:\n",
      "Die besten Parameter: Anzahl der Themen: 8, Alpha: 0.5, Beta: 0.1\n",
      "Der beste Parameter für TF-IDF: Smartire: bxu\n",
      "Koheränz: -0.16646535568787962\n",
      "Perplexität: 12.59058245926554\n",
      "\n",
      "Bestes LSA BoW Model:\n",
      "Der beste Parameter: Anzahl der Themen: 8\n",
      "Koheränz: -0.14661179131805396\n",
      "Perplexität: 158.32630308090606\n",
      "\n",
      "Bestes LSA TF-IDF Model:\n",
      "Der beste Parameter: Anzahl der Themen: 8\n",
      "Der beste Parameter für TF-IDF: Smartire: tpn\n",
      "Koheränz: 0.09307088400127239\n",
      "Perplexität: 134.0274037814177\n",
      "\n",
      "Bestes LDA BoW Model:\n",
      "Die besten Parameter: Anzahl der Themen: 9, Alpha: 0.5, Beta: 0.1\n",
      "Koheränz: -0.18629977221635702\n",
      "Perplexität: 9.114860145283796\n",
      "\n",
      "Bestes LDA TF-IDF Model:\n",
      "Die besten Parameter: Anzahl der Themen: 9, Alpha: 0.5, Beta: 0.02\n",
      "Der beste Parameter für TF-IDF: Smartire: bxu\n",
      "Koheränz: -0.17595597318117764\n",
      "Perplexität: 20.77951649093376\n",
      "\n",
      "Bestes LSA BoW Model:\n",
      "Der beste Parameter: Anzahl der Themen: 9\n",
      "Koheränz: -0.16101603556260968\n",
      "Perplexität: 90.65983210563016\n",
      "\n",
      "Bestes LSA TF-IDF Model:\n",
      "Der beste Parameter: Anzahl der Themen: 9\n",
      "Der beste Parameter für TF-IDF: Smartire: tpn\n",
      "Koheränz: 0.10003473097939172\n",
      "Perplexität: 114.51591689259995\n",
      "\n",
      "Bestes LDA BoW Model:\n",
      "Die besten Parameter: Anzahl der Themen: 10, Alpha: 0.5, Beta: 0.5\n",
      "Koheränz: -0.17286923403916477\n",
      "Perplexität: 8.931392476532649\n",
      "\n",
      "Bestes LDA TF-IDF Model:\n",
      "Die besten Parameter: Anzahl der Themen: 10, Alpha: 0.01, Beta: 0.5\n",
      "Der beste Parameter für TF-IDF: Smartire: bxu\n",
      "Koheränz: -0.16939188260948088\n",
      "Perplexität: 19.01708896018024\n",
      "\n",
      "Bestes LSA BoW Model:\n",
      "Der beste Parameter: Anzahl der Themen: 10\n",
      "Koheränz: -0.15884558376860866\n",
      "Perplexität: 108.22532782249017\n",
      "\n",
      "Bestes LSA TF-IDF Model:\n",
      "Der beste Parameter: Anzahl der Themen: 10\n",
      "Der beste Parameter für TF-IDF: Smartire: tpn\n",
      "Koheränz: 0.08495750389354237\n",
      "Perplexität: 90.69400368750368\n",
      "\n",
      "Bestes LDA BoW Model:\n",
      "Die besten Parameter: Anzahl der Themen: 11, Alpha: 0.5, Beta: 0.5\n",
      "Koheränz: -0.16749279876244058\n",
      "Perplexität: 8.999231566756741\n"
     ]
    }
   ],
   "source": [
    "# Initialize lists to store coherence scores for each method\n",
    "coherence_scores_lda_bow = []\n",
    "coherence_scores_lda_tfidf = []\n",
    "coherence_scores_lsa_bow = []\n",
    "coherence_scores_lsa_tfidf = []\n",
    "\n",
    "perplexity_scores_lda_bow = []\n",
    "perplexity_scores_lda_tfidf = []\n",
    "perplexity_scores_lsa_bow = []\n",
    "perplexity_scores_lsa_tfidf = []\n",
    "\n",
    "best_coherence_lda_bow = -np.inf\n",
    "best_coherence_lda_tfidf = -np.inf\n",
    "best_coherence_lsa_bow = -np.inf\n",
    "best_coherence_lsa_tfidf = -np.inf\n",
    "\n",
    "\n",
    "for n in no_topics:\n",
    "    # LDA BoW\n",
    "    lda_bow_model, lda_bow_corpus, lda_bow_coherence, lda_bow_perplexity = find_best_model(bow_corpus, id2word, data_ready, [n], alpha_list, beta_list, \"LDA BoW\")\n",
    "    coherence_scores_lda_bow.append(lda_bow_coherence)\n",
    "    perplexity_scores_lda_bow.append(lda_bow_perplexity)\n",
    "    if lda_bow_coherence > best_coherence_lda_bow:\n",
    "        best_coherence_lda_bow = lda_bow_coherence\n",
    "        perplexity_lda_bow = lda_bow_perplexity\n",
    "        model_lda_bow = lda_bow_model\n",
    "        corpus_lda_bow = lda_bow_corpus\n",
    "    \n",
    "    # LDA TF-IDF\n",
    "    lda_tfidf_model, lda_tfidf_corpus, lda_tfidf_coherence, lda_tfidf_perplexity = find_best_model(bow_corpus, id2word, data_ready, [n], alpha_list, beta_list, \"LDA TF-IDF\")\n",
    "    coherence_scores_lda_tfidf.append(lda_tfidf_coherence)\n",
    "    perplexity_scores_lda_tfidf.append(lda_tfidf_perplexity)\n",
    "    if lda_tfidf_coherence > best_coherence_lda_tfidf:\n",
    "        best_coherence_lda_tfidf = lda_tfidf_coherence\n",
    "        perplexity_lda_tfidf = lda_tfidf_perplexity\n",
    "        model_lda_tfidf = lda_tfidf_model\n",
    "        corpus_lda_tfidf = lda_tfidf_corpus\n",
    "    \n",
    "    # LSA BoW\n",
    "    lsa_bow_model, lsa_bow_corpus, lsa_bow_coherence, lsa_bow_perplexity = find_best_model(bow_corpus, id2word, data_ready, [n], alpha_list, beta_list, \"LSA BoW\")\n",
    "    coherence_scores_lsa_bow.append(lsa_bow_coherence)\n",
    "    perplexity_scores_lsa_bow.append(lsa_bow_perplexity)\n",
    "    if lsa_bow_coherence > best_coherence_lsa_bow:\n",
    "        best_coherence_lsa_bow = lsa_bow_coherence\n",
    "        perplexity_lsa_bow = lsa_bow_perplexity\n",
    "        model_lsa_bow = lsa_bow_model\n",
    "        corpus_lsa_bow = lsa_bow_corpus\n",
    "    \n",
    "    # LSA TF-IDF\n",
    "    lsa_tfidf_model, lsa_tfidf_corpus, lsa_tfidf_coherence, lsa_tfidf_perplexity = find_best_model(bow_corpus, id2word, data_ready, [n], alpha_list, beta_list, \"LSA TF-IDF\")\n",
    "    coherence_scores_lsa_tfidf.append(lsa_tfidf_coherence)\n",
    "    perplexity_scores_lsa_tfidf.append(lsa_tfidf_perplexity)\n",
    "    if lsa_tfidf_coherence > best_coherence_lsa_tfidf:\n",
    "        best_coherence_lsa_tfidf = lsa_tfidf_coherence\n",
    "        perplexity_lsa_tfidf = lsa_tfidf_perplexity\n",
    "        model_lsa_tfidf = lsa_tfidf_model\n",
    "        corpus_lsa_tfidf = lsa_tfidf_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6bc9733",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_coherence(coherence_scores_lda_bow, coherence_scores_lda_tfidf, coherence_scores_lsa_bow, coherence_scores_lsa_tfidf, no_topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c98e6e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_perplexity(perplexity_scores_lda_bow, perplexity_scores_lda_tfidf, perplexity_scores_lsa_bow, perplexity_scores_lsa_tfidf, no_topics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7eeea61-3543-474c-94fb-fe0d5e69f14c",
   "metadata": {},
   "source": [
    "# Visualisiere die Modelle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa38b78-406b-4214-a2f1-47c0bb4fc6f2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def coherence_per_topic(model, texts, dictionary, model_type):\n",
    "    \n",
    "    coherence_model = CoherenceModel(model=model, texts=texts, dictionary=dictionary, coherence='c_npmi')\n",
    "    coherence_per_topic = coherence_model.get_coherence_per_topic()\n",
    "\n",
    "    # Wandele die Topic-Terme in Strings um\n",
    "    topics_str = [', '.join([term for term, _ in model.show_topic(topic)]) for topic in range(model.num_topics)]\n",
    "\n",
    "    # Erstelle ein DataFrame\n",
    "    topic_score = pd.DataFrame(data=zip(topics_str, coherence_per_topic), columns=['Topic', 'Coherence'])\n",
    "    topic_score = topic_score.set_index('Topic')\n",
    "\n",
    "    # Erstelle die Heatmap\n",
    "    fig, ax = plt.subplots(figsize=(2, 6)) #(10, 6)\n",
    "    \n",
    "    ax.set_title(f\"Themenkohärenz für {str(model)}\\n $C_v$\")\n",
    "    \n",
    "    sns.heatmap(data=topic_score, annot=True, square=True,\n",
    "                cmap='Reds', fmt='.2f',\n",
    "                linecolor='black', ax=ax)\n",
    "    \n",
    "    plt.yticks(rotation=0)\n",
    "    ax.set_xlabel('')\n",
    "    ax.set_ylabel('Themen')\n",
    "    \n",
    "    plt.savefig(f'coherence_per_topic_{model_type}.png', bbox_inches='tight', dpi=150)\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aefd88ad-965f-4e4b-93a1-e73f2b6c0035",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "coherence_per_topic(model_lsa_bow, data_ready, id2word, 'LSA BoW')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa08873-ec9c-491c-acdd-848712954477",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "coherence_per_topic(model_lsa_tfidf, data_ready, id2word, 'LSA TF-IDF')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddba1df7-c5db-42f5-a1de-36f6937ba8c2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "coherence_per_topic(model_lda_bow, data_ready, id2word, 'LDA BoW')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f25b80ba-aec9-42cd-af27-b15d6b1f3ba8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "coherence_per_topic(model_lda_tfidf, data_ready, id2word, 'LDA TF-IDF')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7464199-7adc-4a0b-be2f-77542cdf468c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_topic_distribution(model, corpus, model_type):\n",
    "    dominant_topics = []\n",
    "    topic_percentages = []\n",
    "\n",
    "    for idx, row in enumerate(corpus):\n",
    "        result = model[row]\n",
    "        \n",
    "        # Unpack values from the result\n",
    "        if model_type.startswith(\"LDA\"):\n",
    "            topic_tuples = result[0]\n",
    "            topic_indices, topic_weights = zip(*topic_tuples)\n",
    "        elif model_type.startswith(\"LSA\"):\n",
    "            topic_indices, topic_weights = zip(*result) if result else ([], [])\n",
    "\n",
    "        # Filter out negative weights\n",
    "        non_negative_weights = [(idx, weight) for idx, weight in enumerate(topic_weights) if weight >= 0]\n",
    "\n",
    "        # Sort by weight and get the dominant topic\n",
    "        if non_negative_weights:\n",
    "            dominant_topic = sorted(non_negative_weights, key=lambda x: x[1], reverse=True)[0][0]\n",
    "            dominant_topics.append((idx, dominant_topic))\n",
    "            topic_percentages.append(non_negative_weights)\n",
    "\n",
    "    # Distribution of Dominant Topics in Each Document\n",
    "    df = pd.DataFrame(dominant_topics, columns=['Document_ID', 'Dominant_Topic'])\n",
    "    \n",
    "    dominant_topic = df.groupby('Dominant_Topic').size()\n",
    "    df_dominant_topic = dominant_topic.to_frame(name='count').reset_index()\n",
    "\n",
    "    # Total Topic Distribution by actual weight\n",
    "    topic_weight = pd.DataFrame([dict(t) for t in topic_percentages])\n",
    "    df_topic_weight = topic_weight.sum().to_frame(name='count').reset_index()\n",
    "\n",
    "    # Top Keywords for each Topic\n",
    "    topic_top_words = [(idx, topic) for idx, topics in model.show_topics(formatted=False) \n",
    "                                     for j, (topic, weight) in enumerate(topics) if j < 5]\n",
    "\n",
    "    df_top_words = pd.DataFrame(topic_top_words, columns=['topic_id', 'words'])\n",
    "    df_top_words = df_top_words.groupby('topic_id').agg(', \\n'.join)\n",
    "    df_top_words.reset_index(level=0, inplace=True)\n",
    "    \n",
    "    # Plot\n",
    "    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(14, 8), dpi=150, sharey=True)\n",
    "    \n",
    "    # Adjust the spacing between subplots\n",
    "    plt.subplots_adjust(hspace=0.7)\n",
    "    \n",
    "    # Topic Distribution by Dominant Topics\n",
    "    ax1.bar(x='Dominant_Topic', height='count', data=df_dominant_topic, width=.5, color='firebrick')\n",
    "    ax1.set_xticks(range(df_dominant_topic.Dominant_Topic.unique().__len__()))\n",
    "    \n",
    "    # Add annotations above each bar\n",
    "    for i, count in enumerate(df_dominant_topic['count']):\n",
    "        ax1.text(i, count + 50, str(count), ha='center', va='bottom', fontsize=10, color='black')\n",
    "    \n",
    "    formatter = FuncFormatter(lambda x, pos: 'Thema ' + str(x) + '\\n' + df_top_words.loc[df_top_words.topic_id == x, 'words'].values[0])\n",
    "    ax1.xaxis.set_major_formatter(formatter)\n",
    "    ax1.set_title(f'Anzahl der Dokumente nach vorherrschendem Thema für \\n{model}', fontdict=dict(size=10))\n",
    "    ax1.set_ylabel('Anzahl der Dokumente')\n",
    "    \n",
    "    # Set y-axis limit dynamically\n",
    "    max_count = df_dominant_topic['count'].max()\n",
    "    ax1.set_ylim(0, max_count + 500)\n",
    "\n",
    "    # Topic Distribution by Topic Weights\n",
    "    ax2.bar(x='index', height='count', data=df_topic_weight, width=.5, color='steelblue')\n",
    "    ax2.set_xticks(range(df_topic_weight.index.unique().__len__()))\n",
    "    \n",
    "    # Add annotations above each bar\n",
    "    for i, count in enumerate(df_topic_weight['count']):\n",
    "        ax2.text(i, count + 50, str(round(count, 1)), ha='center', va='bottom', fontsize=10, color='black')\n",
    "    \n",
    "    ax2.xaxis.set_major_formatter(formatter)\n",
    "    ax2.set_title(f'Anzahl der Dokumente nach Themengewichtung für \\n{model}', fontdict=dict(size=10))\n",
    "    \n",
    "    plt.savefig(f'topic_dist_{model_type}.png', bbox_inches='tight', dpi=150)\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "601b1c9f-b428-49a9-b069-53a7e2e4af1f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_topic_distribution(model_lsa_bow, corpus_lsa_bow, 'LSA BoW')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9febc15b-0ace-44ab-9b65-8b9f474e3652",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_topic_distribution(model_lsa_tfidf, corpus_lsa_tfidf, 'LSA TF-IDF')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b9db73e-01a2-4831-93d0-1a542920c529",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_topic_distribution(model_lda_bow, corpus_lda_bow, 'LDA BoW')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c66b761-252c-4722-8724-a327da523493",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_topic_distribution(model_lda_tfidf, corpus_lda_tfidf, 'LDA TF-IDF')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1176499",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for LDA\n",
    "pyLDAvis.enable_notebook()\n",
    "vis = pyLDAvis.gensim_models.prepare(model_lda_tfidf, corpus_lda_tfidf, dictionary=model_lda_tfidf.id2word)\n",
    "vis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52de11cf-0481-419d-bfc5-bd8d0b0ff071",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project_gpu",
   "language": "python",
   "name": "project_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
